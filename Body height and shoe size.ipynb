{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as pplt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy import stats\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "# From this source https://onlinecourses.science.psu.edu/stat200/node/161\n",
    "df = pd.read_excel(\"/Users/isabel/Desktop/SandboxProjects/shoesize.xls\")\n",
    "# so we see this dataset has 408 entries, with each an index, gender string, shoe size and height\n",
    "df.info()\n",
    "# looking at the values, it becomes obvious that this dataset uses US American metric for shoe size and \n",
    "# body height is measured in inches\n",
    "# to convert these values to other metrics is quite bothersome, so it can be a homework task for later\n",
    "#df.head()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot size versus height to get a first impression\n",
    "fontP = FontProperties()\n",
    "fontP.set_size('small')\n",
    "fig = pplt.figure()\n",
    "fig.suptitle('Body height in inches versus shoe size in US size', fontsize=14, fontweight='bold')\n",
    "ax = pplt.subplot(111)\n",
    "\n",
    "#for item in newlistRate:\n",
    "ax.plot(df['Size'],df['Height'], \"o\")#\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "\n",
    "ax.legend(title=\"all data points\",loc='center left', prop = fontP, bbox_to_anchor=(1, 0.5))\n",
    "pplt.show()\n",
    "# the data looks like it's roughly linear, no crazy outliers are visible on this plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a few checks on the data\n",
    "dfshape = df.shape\n",
    "#count number of females in dataset \n",
    "print 'Number of females: ' + str(sum(df['Gender']=='F'))\n",
    "#count number of females in dataset \n",
    "print 'Number of males: ' + str(sum(df['Gender']=='M'))\n",
    "# so here we see that there are more samples of males than females but the proportion is still relatively close\n",
    "\n",
    "#correctness check \n",
    "print 'Do the numbers add up: ' + str((sum(df['Gender']=='F')+sum(df['Gender']=='M') ) == dfshape[0])\n",
    "# the test says that the number of females and males nicely add up to the total number of rows\n",
    "\n",
    "# looking at simple statistics about our data (we can ignore the first column) \n",
    "df.describe()\n",
    "# the data looks valid: shoe size ranges from 5 to 15 and height from 60 to 81 inches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check statistically if this data has a linear correlation\n",
    "print stats.pearsonr(df['Size'],df['Height'])\n",
    "\n",
    "# The first value is close to 0.87 which is relatively close to 1 - this indicates positive linear correlation\n",
    "# The second value is very small, so we can not reject the assumption that this data is uncorrelated\n",
    "\n",
    "# The statistical test confirms our intuition that this data is indeed linearly correlated although not perfectly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's use tensorflow to train a simple model to learn a regression for this task\n",
    "# ADAPT THIS PART !!!\n",
    "# Data and model preparation for NN learning\n",
    "\n",
    "# pediction of Dalc\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "\n",
    "# Our model is a standard 1-hidden-layer multi-layer-perceptron with ReLU\n",
    "# activation. The softmax (which turns arbitrary real-valued outputs into\n",
    "# probabilities) gets applied in the cost function.\n",
    "def model(X, w_h, w_o):\n",
    "    h = tf.nn.relu(tf.matmul(X, w_h))\n",
    "    return tf.matmul(h, w_o)\n",
    "# How many units in the hidden layer + batch size\n",
    "NUM_HIDDEN = 200\n",
    "BATCH_SIZE = 128\n",
    "# Our variables. The input has width NUM_Feat, and the output has width 5\n",
    "X = tf.placeholder(\"float\", [None, num_feat])\n",
    "Y = tf.placeholder(\"float\", [None, 5])\n",
    "\n",
    "\n",
    "#w = init_weights([num_feat, 1]) # like in linear regression, we need a shared variable weight matrix for logistic regression\n",
    "w_h = init_weights([num_feat, NUM_HIDDEN])\n",
    "w_o = init_weights([NUM_HIDDEN, 5])\n",
    "\n",
    "#y = tf.matmul(tf.nn.relu(tf.matmul(X, w_h)), w_o)\n",
    "y = tf.matmul(tf.nn.relu(tf.matmul(X, w_h)), w_o)\n",
    "# Predict y given x using the model.\n",
    "py_x = model(X, w_h, w_o)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y))\n",
    "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\n",
    "predict_op = tf.argmax(py_x, 1) # at predict time, evaluate the argmax \n",
    "\n",
    "p = np.random.permutation(range(len(dfs)))\n",
    "allX, allY = dfs[p], Y_data[p]\n",
    "border = int(0.8*num_samples)\n",
    "hotY = pd.get_dummies(allY)\n",
    "hoty = hotY.as_matrix()\n",
    "\n",
    "trX = allX[:border]\n",
    "teX = allX[border:]\n",
    "trY = hoty[:border]\n",
    "teY = hoty[border:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Launch the graph in an interactive session\n",
    "sess = tf.InteractiveSession()\n",
    "tf.initialize_all_variables().run()\n",
    "\n",
    "for epoch in range(400):\n",
    "    # Shuffle the data before each training iteration.\n",
    "    p = np.random.permutation(range(len(trX)))\n",
    "    trX, trY = trX[p], trY[p]\n",
    "\n",
    "    # Train in batches \n",
    "    for start in range(0, len(trX), BATCH_SIZE):\n",
    "        end = start + BATCH_SIZE        \n",
    "        sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "\n",
    "        \n",
    "    # And print the current accuracy on the training data.\n",
    "    if epoch % 20==0:\n",
    "        #compute accuracy\n",
    "        correct_prediction = tf.equal(tf.cast(tf.argmax(y,1), tf.float32),tf.cast(tf.argmax(Y,1), tf.float32) )\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        result = sess.run(accuracy, feed_dict={X: trX[start:end], Y: trY[start:end]})\n",
    "        print 'Run {}, {}'.format(epoch+1, result)\n",
    "        \n",
    "        # average weight filter\n",
    "        wb = sess.run(w_h)\n",
    "        print np.mean(wb) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check test error\n",
    "correct_prediction = tf.equal(tf.cast(tf.argmax(y,1), tf.float32),tf.cast(tf.argmax(Y,1), tf.float32) )\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "result = sess.run(accuracy, feed_dict={X: teX[:], Y: teY[:]})\n",
    "print 'Evaluation on test data {}'.format(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Close the Session when we're done.\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
